{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "#!apt update && apt install python-pydot python-pydot-ng graphviz -y\n",
    "#!pip install graphviz\n",
    "#!pip install torchviz\n",
    "#!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torchvision.models\n",
    "\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from Models.Perceiver_archs.perceiver_module import (\n",
    "    PerceiverEncoder, PerceiverDecoder, PerceiverIO\n",
    ")\n",
    "from Models.Perceiver_archs.task_spec_adapter import (\n",
    "    Image_FourierEnc, ClassificationOutputAdapter\n",
    ")\n",
    "\n",
    "# Fourier-encodes pixel positions and flattens along spatial dimensions\n",
    "input_adapter = Image_FourierEnc(\n",
    "    image_shape=(224, 224, 3),  # M = 224 * 224\n",
    "    num_frequency_bands=64,\n",
    ")\n",
    "# Projects generic Perceiver decoder output to specified number of classes\n",
    "output_adapter = ClassificationOutputAdapter(\n",
    "    num_classes=1000,  # E\n",
    "    num_output_query_channels=1024  # F\n",
    ")\n",
    "\n",
    "# Generic Perceiver encoder\n",
    "encoder = PerceiverEncoder(\n",
    "    input_adapter=input_adapter,\n",
    "    num_latents=512,  # N\n",
    "    num_latent_channels=1024,  # D\n",
    "    num_cross_attention_qk_channels=input_adapter.num_input_channels,  # C\n",
    "    num_cross_attention_heads=1,\n",
    "    num_self_attention_heads=2,\n",
    "    num_self_attention_layers_per_block=2,\n",
    "    num_self_attention_blocks=3,\n",
    "    dropout=0.0,\n",
    ")\n",
    "# Generic Perceiver decoder\n",
    "decoder = PerceiverDecoder(\n",
    "    output_adapter=output_adapter,\n",
    "    num_latent_channels=1024,  # D\n",
    "    num_cross_attention_heads=1,\n",
    "    dropout=0.0,\n",
    ")\n",
    "# Perceiver IO image classifier\n",
    "model = PerceiverIO(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "  Image_FourierEnc-1           [-1, 50176, 261]               0\n",
      "         LayerNorm-2            [-1, 512, 1024]           2,048\n",
      "         LayerNorm-3           [-1, 50176, 261]             522\n",
      "            Linear-4             [-1, 512, 261]         267,525\n",
      "            Linear-5           [-1, 50176, 261]          68,382\n",
      "            Linear-6           [-1, 50176, 261]          68,382\n",
      "           Dropout-7           [-1, 512, 50176]               0\n",
      "            Linear-8            [-1, 512, 1024]         268,288\n",
      "MultiHeadAttention-9            [-1, 512, 1024]               0\n",
      "   CrossAttention-10            [-1, 512, 1024]               0\n",
      "          Dropout-11            [-1, 512, 1024]               0\n",
      "         Residual-12            [-1, 512, 1024]               0\n",
      "        LayerNorm-13            [-1, 512, 1024]           2,048\n",
      "           Linear-14            [-1, 512, 1024]       1,049,600\n",
      "             GELU-15            [-1, 512, 1024]               0\n",
      "           Linear-16            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-17            [-1, 512, 1024]               0\n",
      "         Residual-18            [-1, 512, 1024]               0\n",
      "        LayerNorm-19            [-1, 512, 1024]           2,048\n",
      "           Linear-20            [-1, 512, 1024]       1,049,600\n",
      "           Linear-21            [-1, 512, 1024]       1,049,600\n",
      "           Linear-22            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-23             [-1, 512, 512]               0\n",
      "           Linear-24            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-25            [-1, 512, 1024]               0\n",
      "    SelfAttention-26            [-1, 512, 1024]               0\n",
      "          Dropout-27            [-1, 512, 1024]               0\n",
      "         Residual-28            [-1, 512, 1024]               0\n",
      "        LayerNorm-29            [-1, 512, 1024]           2,048\n",
      "           Linear-30            [-1, 512, 1024]       1,049,600\n",
      "             GELU-31            [-1, 512, 1024]               0\n",
      "           Linear-32            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-33            [-1, 512, 1024]               0\n",
      "         Residual-34            [-1, 512, 1024]               0\n",
      "        LayerNorm-35            [-1, 512, 1024]           2,048\n",
      "           Linear-36            [-1, 512, 1024]       1,049,600\n",
      "           Linear-37            [-1, 512, 1024]       1,049,600\n",
      "           Linear-38            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-39             [-1, 512, 512]               0\n",
      "           Linear-40            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-41            [-1, 512, 1024]               0\n",
      "    SelfAttention-42            [-1, 512, 1024]               0\n",
      "          Dropout-43            [-1, 512, 1024]               0\n",
      "         Residual-44            [-1, 512, 1024]               0\n",
      "        LayerNorm-45            [-1, 512, 1024]           2,048\n",
      "           Linear-46            [-1, 512, 1024]       1,049,600\n",
      "             GELU-47            [-1, 512, 1024]               0\n",
      "           Linear-48            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-49            [-1, 512, 1024]               0\n",
      "         Residual-50            [-1, 512, 1024]               0\n",
      "        LayerNorm-51            [-1, 512, 1024]           2,048\n",
      "           Linear-52            [-1, 512, 1024]       1,049,600\n",
      "           Linear-53            [-1, 512, 1024]       1,049,600\n",
      "           Linear-54            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-55             [-1, 512, 512]               0\n",
      "           Linear-56            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-57            [-1, 512, 1024]               0\n",
      "    SelfAttention-58            [-1, 512, 1024]               0\n",
      "          Dropout-59            [-1, 512, 1024]               0\n",
      "         Residual-60            [-1, 512, 1024]               0\n",
      "        LayerNorm-61            [-1, 512, 1024]           2,048\n",
      "           Linear-62            [-1, 512, 1024]       1,049,600\n",
      "             GELU-63            [-1, 512, 1024]               0\n",
      "           Linear-64            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-65            [-1, 512, 1024]               0\n",
      "         Residual-66            [-1, 512, 1024]               0\n",
      "        LayerNorm-67            [-1, 512, 1024]           2,048\n",
      "           Linear-68            [-1, 512, 1024]       1,049,600\n",
      "           Linear-69            [-1, 512, 1024]       1,049,600\n",
      "           Linear-70            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-71             [-1, 512, 512]               0\n",
      "           Linear-72            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-73            [-1, 512, 1024]               0\n",
      "    SelfAttention-74            [-1, 512, 1024]               0\n",
      "          Dropout-75            [-1, 512, 1024]               0\n",
      "         Residual-76            [-1, 512, 1024]               0\n",
      "        LayerNorm-77            [-1, 512, 1024]           2,048\n",
      "           Linear-78            [-1, 512, 1024]       1,049,600\n",
      "             GELU-79            [-1, 512, 1024]               0\n",
      "           Linear-80            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-81            [-1, 512, 1024]               0\n",
      "         Residual-82            [-1, 512, 1024]               0\n",
      "        LayerNorm-83            [-1, 512, 1024]           2,048\n",
      "           Linear-84            [-1, 512, 1024]       1,049,600\n",
      "           Linear-85            [-1, 512, 1024]       1,049,600\n",
      "           Linear-86            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-87             [-1, 512, 512]               0\n",
      "           Linear-88            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-89            [-1, 512, 1024]               0\n",
      "    SelfAttention-90            [-1, 512, 1024]               0\n",
      "          Dropout-91            [-1, 512, 1024]               0\n",
      "         Residual-92            [-1, 512, 1024]               0\n",
      "        LayerNorm-93            [-1, 512, 1024]           2,048\n",
      "           Linear-94            [-1, 512, 1024]       1,049,600\n",
      "             GELU-95            [-1, 512, 1024]               0\n",
      "           Linear-96            [-1, 512, 1024]       1,049,600\n",
      "          Dropout-97            [-1, 512, 1024]               0\n",
      "         Residual-98            [-1, 512, 1024]               0\n",
      "        LayerNorm-99            [-1, 512, 1024]           2,048\n",
      "          Linear-100            [-1, 512, 1024]       1,049,600\n",
      "          Linear-101            [-1, 512, 1024]       1,049,600\n",
      "          Linear-102            [-1, 512, 1024]       1,049,600\n",
      "         Dropout-103             [-1, 512, 512]               0\n",
      "          Linear-104            [-1, 512, 1024]       1,049,600\n",
      "MultiHeadAttention-105            [-1, 512, 1024]               0\n",
      "   SelfAttention-106            [-1, 512, 1024]               0\n",
      "         Dropout-107            [-1, 512, 1024]               0\n",
      "        Residual-108            [-1, 512, 1024]               0\n",
      "       LayerNorm-109            [-1, 512, 1024]           2,048\n",
      "          Linear-110            [-1, 512, 1024]       1,049,600\n",
      "            GELU-111            [-1, 512, 1024]               0\n",
      "          Linear-112            [-1, 512, 1024]       1,049,600\n",
      "         Dropout-113            [-1, 512, 1024]               0\n",
      "        Residual-114            [-1, 512, 1024]               0\n",
      "PerceiverEncoder-115            [-1, 512, 1024]               0\n",
      "       LayerNorm-116              [-1, 1, 1024]           2,048\n",
      "       LayerNorm-117            [-1, 512, 1024]           2,048\n",
      "          Linear-118              [-1, 1, 1024]       1,049,600\n",
      "          Linear-119            [-1, 512, 1024]       1,049,600\n",
      "          Linear-120            [-1, 512, 1024]       1,049,600\n",
      "         Dropout-121               [-1, 1, 512]               0\n",
      "          Linear-122              [-1, 1, 1024]       1,049,600\n",
      "MultiHeadAttention-123              [-1, 1, 1024]               0\n",
      "  CrossAttention-124              [-1, 1, 1024]               0\n",
      "         Dropout-125              [-1, 1, 1024]               0\n",
      "        Residual-126              [-1, 1, 1024]               0\n",
      "       LayerNorm-127              [-1, 1, 1024]           2,048\n",
      "          Linear-128              [-1, 1, 1024]       1,049,600\n",
      "            GELU-129              [-1, 1, 1024]               0\n",
      "          Linear-130              [-1, 1, 1024]       1,049,600\n",
      "         Dropout-131              [-1, 1, 1024]               0\n",
      "        Residual-132              [-1, 1, 1024]               0\n",
      "          Linear-133              [-1, 1, 1000]       1,025,000\n",
      "ClassificationOutputAdapter-134                 [-1, 1000]               0\n",
      "PerceiverDecoder-135                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 47,915,315\n",
      "Trainable params: 47,915,315\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1032.80\n",
      "Params size (MB): 182.78\n",
      "Estimated Total Size (MB): 1216.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# arch summary \n",
    "model = model.cuda()\n",
    "summary(model, img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Models/example.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Visualization\n",
    "# do not forgot to place in cpu..\n",
    "model = model.cpu()\n",
    "\n",
    "# build pipeline :\n",
    "x = torch.randn((1, 224, 224, 3))\n",
    "#enc_emb = encoder(x)\n",
    "#out = decoder(enc_emb)\n",
    "out = model(x)\n",
    "\n",
    "make_dot(out, params=dict(model.named_parameters()), show_attrs=False, show_saved=False).render(\"./Models/example\", format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Jun 29 2022, 11:45:57) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
